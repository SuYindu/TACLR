defaults:
  - base_config

paradigm: "generation"
model_name: "meta-llama/Llama-3.1-8B-Instruct"

do_train: false
do_eval: true
per_device_eval_batch_size: 16

n_shots: 0

bf16: true 